[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Datos++",
    "section": "",
    "text": "Bienvenidos a “Datos++”. Este libro integra teoría y práctica mediante notebooks interactivos que combinan explicaciones, código ejecutable y ejercicios. Está diseñado para la asignatura Ingeniería de Datos de la carrera de Ingeniería Informática en la Universidad de La Frontera."
  },
  {
    "objectID": "index.html#un-puente-entre-la-teoría-y-la-práctica",
    "href": "index.html#un-puente-entre-la-teoría-y-la-práctica",
    "title": "Datos++",
    "section": "",
    "text": "Bienvenidos a “Datos++”. Este libro integra teoría y práctica mediante notebooks interactivos que combinan explicaciones, código ejecutable y ejercicios. Está diseñado para la asignatura Ingeniería de Datos de la carrera de Ingeniería Informática en la Universidad de La Frontera."
  },
  {
    "objectID": "association-rules/00_ejemplo_1.1.html",
    "href": "association-rules/00_ejemplo_1.1.html",
    "title": "Introducción a las Reglas de Asociación",
    "section": "",
    "text": "Las reglas de asociación son una técnica de minería de datos que permite descubrir relaciones interesantes entre variables en grandes conjuntos de datos. Estas reglas son especialmente útiles en el análisis de datos de transacciones, como los registros de ventas en un supermercado. Vamos a crear un ejemplo didáctico para entender cómo funcionan.\n\n\nDefiniciones\nÍtem (Item): Un ítem es un producto o artículo individual que se vende en una transacción. En el contexto de las reglas de asociación, un conjunto de ítems se refiere a uno o más productos que se compran juntos en una transacción.\n\nSoporte (Support): Es la proporción de transacciones que contienen un conjunto de ítems específico. Ayuda a identificar cuán común es un conjunto de ítems en el conjunto de datos.\n\\[\n\\text{Soporte} = \\frac{\\text{Número de transacciones que contienen el conjunto de ítems}}{\\text{Número total de transacciones}}\n\\]\n\nExplicación:\n\nEl soporte mide la frecuencia con la que un conjunto de ítems aparece en el conjunto de datos.\nEs útil porque nos ayuda a identificar cuáles combinaciones de productos son comunes en nuestras transacciones.\nPor ejemplo, si el soporte de “leche y pan” es alto, significa que estos productos se compran juntos con frecuencia.\n\n\nConfianza (Confidence): Es la proporción de transacciones que contienen el conjunto de ítems A que también contienen el conjunto de ítems B. Indica la probabilidad de que B se compre cuando A se compra.\n\\[\n\\text{Confianza}(A \\rightarrow B) = \\frac{\\text{Soporte}(A \\cup B)}{\\text{Soporte}(A)}\n\\]\n\nExplicación:\n\nLa confianza mide la probabilidad de que el ítem B sea comprado cuando el ítem A ya ha sido comprado.\nEs útil para entender la fuerza de la regla de asociación.\nPor ejemplo, una confianza del 75% para la regla “leche \\(\\rightarrow\\) pan” significa que el 75% de las veces que los clientes compran leche, también compran pan.\n\n\nLift: Mide la relación entre la ocurrencia de A y B. Indica cuánto más probable es que B se compre cuando A se compra, en comparación con la probabilidad de comprar B sin A.\n\\[\n\\text{Lift}(A \\rightarrow B) = \\frac{\\text{Confianza}(A \\rightarrow B)}{\\text{Soporte}(B)}\n\\]\n\nExplicación:\n\nEl lift mide la relación entre la ocurrencia de A y B en comparación con su ocurrencia esperada si fueran independientes.\nUn lift mayor a 1 indica que A y B ocurren juntos más a menudo de lo esperado si fueran independientes.\nEs útil para identificar relaciones significativas entre productos.\nPor ejemplo, si el lift de “leche \\(\\rightarrow\\) pan” es 1.125, significa que los clientes que compran leche son 1.125 veces más propensos a comprar pan que el promedio de todos los clientes.\n\n\n\n\n\nEjemplo\n\nImaginemos que gestionas un pequeño supermercado y tienes los datos de las transacciones de los últimos meses.\nQuieres analizar estos datos para descubrir patrones en las compras de tus clientes, es decir, qué productos suelen comprarse juntos.\n\n\n\nDatos\nSupongamos que tenemos las siguientes transacciones:\n\nTransacción 1: Leche, Pan, Mantequilla\nTransacción 2: Leche, Pan\nTransacción 3: Leche, Manzana\nTransacción 4: Pan, Mantequilla\nTransacción 5: Leche, Pan, Mantequilla, Manzana\nTransacción 6: Manzana, Mantequilla\n\n\nPaso 1: Crear la Matriz de Transacciones\n\nPrimero, representamos las transacciones en una matriz donde cada fila representa una transacción y cada columna representa un producto.\nUsamos 1 para indicar que un producto se compró en esa transacción y 0 en caso contrario.\n\n\n\n\n\nLeche\nPan\nMantequilla\nManzana\n\n\n\n\nT1\n1\n1\n1\n0\n\n\nT2\n1\n1\n0\n0\n\n\nT3\n1\n0\n0\n1\n\n\nT4\n0\n1\n1\n0\n\n\nT5\n1\n1\n1\n1\n\n\nT6\n0\n0\n1\n1\n\n\n\n\n\nPaso 2: Identificar Patrones Frecuentes\n\nPara identificar patrones frecuentes, calculamos el soporte de cada combinación de productos.\nEl soporte es la proporción de transacciones en las que aparece una combinación de productos.\n\nSoporte:\n\nSoporte de \\(\\{Leche\\}\\) = 4/6\nSoporte de \\(\\{Pan\\}\\) = 4/6\nSoporte de \\(\\{Mantequilla\\}\\) = 4/6\nSoporte de \\(\\{Manzana\\}\\) = 3/6\nSoporte de \\(\\{Leche, Pan\\}\\) = 3/6\nSoporte de \\(\\{Leche, Mantequilla\\}\\) = 2/6\nSoporte de \\(\\{Pan, Mantequilla\\}\\) = 3/6\nSoporte de \\(\\{Leche, Manzana\\}\\) = 2/6\nSoporte de \\(\\{Pan, Manzana\\}\\) = 1/6\nSoporte de \\(\\{Mantequilla, Manzana\\}\\) = 2/6\n\n\n\nPaso 3: Generar Reglas de Asociación\n\nUna vez identificados los patrones frecuentes, generamos reglas de asociación.\nEstas reglas tienen la forma \\(A \\rightarrow B\\), donde A (antecedente) y B (consecuente) son conjuntos de productos.\nPara cada regla, calculamos la confianza y el lift.\nUna vez identificados los patrones frecuentes, generamos reglas de asociación.\n\nReglas:\n\nRegla: \\(\\{Leche\\} -&gt; \\{Pan\\}\\)\n\n\\[Confianza = \\frac{\\text{Soporte}(\\{Leche, Pan\\})}{\\text{Soporte}(\\{Leche\\})} = \\frac{3/6}{4/6} = 0.75\\]\n\\[Lift = \\frac{\\text{Confianza}}{\\text{Soporte}(\\{Pan\\})} = \\frac{0.75}{4/6} = 1.125\\]\n\nRegla: {Pan} -&gt; {Leche}\n\n\\[Confianza = \\frac{\\text{Soporte}(\\{Leche, Pan\\})}{\\text{Soporte}(\\{Pan\\})} = \\frac{3/6}{4/6} = 0.75\\]\n\\[Lift = \\frac{\\text{Confianza}}{\\text{Soporte}(\\{Leche\\})} = \\frac{0.75}{4/6} = 1.125\\]\n\n\n\n\nPaso 4: Interpretación\n\nLa regla \\(\\{Leche\\} \\rightarrow \\{Pan\\}\\) con una confianza de 0.75 significa que el 75% de las veces que los clientes compran leche, también compran pan.\nUn lift de 1.125 indica una leve relación positiva entre la compra de leche y pan, sugiriendo que comprar leche aumenta la probabilidad de que también se compre pan.\n\n\nimport pandas as pd\n\n# Crear el dataframe con las transacciones\ndata = {\n    'Leche': [1, 1, 1, 0, 1, 0],\n    'Pan': [1, 1, 0, 1, 1, 0],\n    'Mantequilla': [1, 0, 0, 1, 1, 1],\n    'Manzana': [0, 0, 1, 0, 1, 1]\n}\n\ndf = pd.DataFrame(data, index=['T1', 'T2', 'T3', 'T4', 'T5', 'T6'])\nprint(df)\n\n    Leche  Pan  Mantequilla  Manzana\nT1      1    1            1        0\nT2      1    1            0        0\nT3      1    0            0        1\nT4      0    1            1        0\nT5      1    1            1        1\nT6      0    0            1        1\n\n\n\nimport gradio as gr\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Función de prueba que hace predicciones según parámetros\ndef hacer_predicciones(param1: float, param2: int, texto: str):\n    # Retorna una tabla de resultados + una gráfica\n    df = pd.DataFrame({\n        \"entrada\": [texto],\n        \"predicción\": [\"clase A\"], \n        \"probabilidad\": [0.82]\n    })\n    fig, ax = plt.subplots()\n    ax.bar([\"clase A\", \"clase B\"], [0.82, 0.18])\n    ax.set_ylabel(\"Probabilidad\")\n    return df, fig\n\n# Interfaz Gradio\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Experimento interactivo del capítulo de Predicciones\")\n    param1 = gr.Slider(0.0, 1.0, value=0.5, label=\"Parámetro 1\")\n    param2 = gr.Slider(1, 10, value=3, label=\"Parámetro 2\")\n    texto = gr.Textbox(lines=3, label=\"Texto de entrada\")\n    boton = gr.Button(\"Predecir\")\n\n    tabla = gr.Dataframe(headers=[\"entrada\", \"predicción\", \"probabilidad\"])\n    graf = gr.Plot()\n\n    boton.click(fn=hacer_predicciones, inputs=[param1, param2, texto], outputs=[tabla, graf])\n\n    # Algunos ejemplos extraídos del libro\n    demos = [\n        [0.5, 3, \"Texto de ejemplo\"],\n        [0.8, 5, \"Otro ejemplo\"]\n    ]\n    gr.Examples(demos, inputs=[param1, param2, texto])\n    \ndemo.launch(share=True)\n\n/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://89488052ca5b3d5447.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)",
    "crumbs": [
      "Reglas de Asociación",
      "Introducción a las Reglas de Asociación"
    ]
  },
  {
    "objectID": "classification/classification_ransomware.html",
    "href": "classification/classification_ransomware.html",
    "title": "Ransomware detection",
    "section": "",
    "text": "Este dataset contiene 21,752 muestras balanceadas, de las cuales 10,876 son maliciosas y 10,876 benignas. Las muestras maliciosas están distribuidas en 26 familias distintas, incluyendo un enfoque particular en ransomware, con familias reconocidas como Cerber, DarkSide, GandCrab, Ryuk y WannaCry, entre otras.\nEl objetivo principal es entrenar modelos de clasificación capaces de distinguir entre archivos maliciosos y benignos, evaluando su desempeño mediante métricas como precisión, recall, f1-score y exactitud.\nEl dataset contiene características relevantes de cada archivo, que serán procesadas, limpiadas y transformadas para generar los conjuntos de entrenamiento y prueba. La variable objetivo es Class, que indica si un archivo es malicioso (1) o benigno (0).\nPLANNING: - INTRO - short dataset description. - EDA - shape, dtypes, missing, class balance, sample rows, correlations. - PREPARING DATA - drop useless columns, fix dtype issues, parse timestamps, coerce numerics, encode label. - DATA SPLITTING - splitting training and testing data. - RESULTS - early results. - PREPARING MODELS - prepare hyperparameter, baseline models. - RESULTS WITH MULTIPLES MODELS- metrics (precision/recall/f1), confusion matrix. - BALANCING - try balancing and compare. - RESULTS (after balancing) - compare metrics. - CONCLUSION - state best model, tradeoffs, next steps.",
    "crumbs": [
      "Clasificación",
      "Ransomware detection"
    ]
  },
  {
    "objectID": "classification/classification_ransomware.html#importamos-las-librerías-necesarias-y-cargamos-el-dataset",
    "href": "classification/classification_ransomware.html#importamos-las-librerías-necesarias-y-cargamos-el-dataset",
    "title": "Ransomware detection",
    "section": "Importamos las librerías necesarias y cargamos el dataset",
    "text": "Importamos las librerías necesarias y cargamos el dataset\n\nimport pandas as pd\nfrom pathlib import Path\n\nbase_dir = Path.cwd()\ncsv_file_path = base_dir.parent.parent / \"data\" / \"raw_data\" / \"ransom.csv\"\ndata = pd.read_csv(csv_file_path, low_memory=False, index_col=0)\n# Para hacer más rápido el procesamiento, tomamos una muestra del dataset\ndf = data.sample(n=1000, random_state=42)\ndf.head(1)\n\n\n\n\n\n\n\n\nsha1\nfile_extension\nEntryPoint\nPEType\nMachineType\nmagic_number\nbytes_on_last_page\npages_in_file\nrelocations\nsize_of_header\n...\ntotal_procsses\nfiles_malicious\nfiles_suspicious\nfiles_text\nfiles_unknown\ndlls_calls\napis\nClass\nCategory\nFamily\n\n\nmd5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8742c015240d3807cda31988658f2b80\n7e89a31bbcbc780f3e2adc777995501f86079d6e\nexe\n0x34a4\nPE32\nIntel 386 or later, and compatibles\nMZ\n0x0090\n0x0003\n0x0004\n0x0000\n...\n36.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nBenign\nBenign\nBenign\n\n\n\n\n1 rows × 76 columns",
    "crumbs": [
      "Clasificación",
      "Ransomware detection"
    ]
  },
  {
    "objectID": "classification/classification_ransomware.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "href": "classification/classification_ransomware.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "title": "Ransomware detection",
    "section": "Realizamos un analisis exploratorio sobre los datos",
    "text": "Realizamos un analisis exploratorio sobre los datos\n\nExploramos la forma general del dataset\n\n# Realizamos un analysis exploratorio sobre los datos\nprint(\"Shape:\", df.shape)\nprint(\"\\nColumns and dtypes:\")\nprint(df.dtypes)\nprint(\"\\nNumeric summary (describe):\")\ndisplay(df.describe().T)\n\nShape: (1000, 76)\n\nColumns and dtypes:\nsha1               object\nfile_extension     object\nEntryPoint         object\nPEType             object\nMachineType        object\n                   ...   \ndlls_calls        float64\napis              float64\nClass              object\nCategory           object\nFamily             object\nLength: 76, dtype: object\n\nNumeric summary (describe):\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nregistry_read\n1000.0\n1969.901\n12792.143237\n0.0\n23.00\n213.5\n898.25\n359646.0\n\n\nregistry_write\n1000.0\n15.826\n84.838194\n0.0\n0.00\n0.0\n3.00\n1448.0\n\n\nregistry_delete\n1000.0\n1.908\n18.058284\n0.0\n0.00\n0.0\n0.00\n298.0\n\n\nregistry_total\n1000.0\n2063.848\n13027.855054\n0.0\n22.75\n221.0\n918.75\n365999.0\n\n\nnetwork_threats\n1000.0\n0.000\n0.000000\n0.0\n0.00\n0.0\n0.00\n0.0\n\n\nnetwork_dns\n1000.0\n4.134\n27.120538\n0.0\n0.00\n0.0\n1.00\n568.0\n\n\nnetwork_http\n1000.0\n1.675\n13.845543\n0.0\n0.00\n0.0\n0.00\n318.0\n\n\nnetwork_connections\n1000.0\n21.927\n174.432217\n0.0\n0.00\n2.0\n5.00\n2192.0\n\n\nprocesses_malicious\n1000.0\n1.835\n10.217151\n0.0\n0.00\n1.0\n2.00\n314.0\n\n\nprocesses_suspicious\n1000.0\n0.359\n2.548846\n0.0\n0.00\n0.0\n0.00\n70.0\n\n\nprocesses_monitored\n1000.0\n9.437\n54.572192\n0.0\n1.00\n2.0\n5.00\n1605.0\n\n\ntotal_procsses\n1000.0\n42.929\n58.420929\n0.0\n34.00\n37.0\n43.00\n1643.0\n\n\nfiles_malicious\n1000.0\n5.892\n30.643815\n0.0\n0.00\n0.0\n1.00\n551.0\n\n\nfiles_suspicious\n1000.0\n359.543\n2003.727509\n0.0\n0.00\n0.0\n4.00\n34060.0\n\n\nfiles_text\n1000.0\n71.734\n331.357745\n0.0\n0.00\n0.0\n3.00\n5947.0\n\n\nfiles_unknown\n1000.0\n23.166\n167.367082\n0.0\n0.00\n0.0\n0.00\n4415.0\n\n\ndlls_calls\n1000.0\n4.591\n5.780236\n0.0\n1.00\n2.0\n7.00\n50.0\n\n\napis\n1000.0\n91.538\n138.579663\n0.0\n1.00\n23.0\n127.00\n953.0\n\n\n\n\n\n\n\n\n\nVerificamos valores nulos\n\n# Resumen de valores nulos\n\nmissing_counts = df.isna().sum()\nmissing_percent = 100 * missing_counts / len(df)\nmissing_summary = pd.concat([missing_counts, missing_percent], axis=1)\nmissing_summary.columns = [\"nulos\", \"porcentaje\"]\nprint(\"\\nNulos por columna (n y %):\")\ndisplay(missing_summary.sort_values(\"nulos\", ascending=False).head(20))\n\n\nNulos por columna (n y %):\n\n\n\n\n\n\n\n\n\nnulos\nporcentaje\n\n\n\n\nsha1\n0\n0.0\n\n\nfile_extension\n0\n0.0\n\n\nEntryPoint\n0\n0.0\n\n\nPEType\n0\n0.0\n\n\nMachineType\n0\n0.0\n\n\nmagic_number\n0\n0.0\n\n\nbytes_on_last_page\n0\n0.0\n\n\npages_in_file\n0\n0.0\n\n\nrelocations\n0\n0.0\n\n\nsize_of_header\n0\n0.0\n\n\nmin_extra_paragraphs\n0\n0.0\n\n\nmax_extra_paragraphs\n0\n0.0\n\n\ninit_ss_value\n0\n0.0\n\n\ninit_sp_value\n0\n0.0\n\n\ninit_ip_value\n0\n0.0\n\n\ninit_cs_value\n0\n0.0\n\n\nover_lay_number\n0\n0.0\n\n\noem_identifier\n0\n0.0\n\n\naddress_of_ne_header\n0\n0.0\n\n\nMagic\n0\n0.0\n\n\n\n\n\n\n\nRevisamos su distribution\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntarget_col = \"Class\"\nfigsize = (6, 4)\n\n# Muestra los conteos y porcentajes para la variable binaria objetivo\n\nvc = df[target_col].value_counts(dropna=False)\npct = (vc / len(df) * 100).round(2)\nprint(\"Counts:\")\nprint(vc)\nprint(\"\\nPercent:\")\nprint(pct)\n\nplt.figure(figsize=figsize)\nsns.barplot(x=vc.index.astype(str), y=vc.values)\nplt.title(f\"Target distribution: {target_col}\")\nplt.ylabel(\"count\")\nplt.xlabel(target_col)\nplt.show()\n\nCounts:\nClass\nMalware    504\nBenign     496\nName: count, dtype: int64\n\nPercent:\nClass\nMalware    50.4\nBenign     49.6\nName: count, dtype: float64",
    "crumbs": [
      "Clasificación",
      "Ransomware detection"
    ]
  },
  {
    "objectID": "classification/classification_software_defects.html",
    "href": "classification/classification_software_defects.html",
    "title": "Software Defects analysis",
    "section": "",
    "text": "Software Defects Multilingual Dataset with AST & Token Features (2025), un conjunto de datos sintético diseñado para el estudio de predicción de defectos en software y la análisis estático de código en múltiples lenguajes de programación. Predecimoses entrenar modelos de machine learning capaces de predecir si una función de código contiene defectos o no, basándose en métricas estáticas (tokens, complejidad, estructuras de control, etc.).\nPLANNING: - INTRO - short dataset description. - EDA - shape, dtypes, missing, class balance, sample rows, correlations. - PREPARING DATA - drop useless columns, fix dtype issues, parse timestamps, coerce numerics, encode label. - DATA SPLITTING - splitting training and testing data. - RESULTS - early results. - PREPARING MODELS - prepare hyperparameter, baseline models. - RESULTS WITH MULTIPLES MODELS- metrics (precision/recall/f1), confusion matrix. - BALANCING - try balancing and compare. - RESULTS (after balancing) - compare metrics. - CONCLUSION - state best model, tradeoffs, next steps.",
    "crumbs": [
      "Clasificación",
      "Software Defects analysis"
    ]
  },
  {
    "objectID": "classification/classification_software_defects.html#importamos-las-librerías-necesarias-y-cargamos-el-dataset",
    "href": "classification/classification_software_defects.html#importamos-las-librerías-necesarias-y-cargamos-el-dataset",
    "title": "Software Defects analysis",
    "section": "Importamos las librerías necesarias y cargamos el dataset",
    "text": "Importamos las librerías necesarias y cargamos el dataset\n\nimport pandas as pd\nfrom pathlib import Path\n\nbase_dir = Path.cwd()\ncsv_file_path = base_dir.parent.parent / \"data\" / \"software_defects\" / \"software_defects.csv\"\ndf = pd.read_csv(csv_file_path, low_memory=False, index_col=0)\ndf.head(1)\n\n\n\n\n\n\n\n\ncode\nlanguage\nlines_of_code\ncyclomatic_complexity\ntoken_count\nnum_ifs\nnum_returns\nnum_func_calls\nast_nodes\ndefect\n\n\nfunction_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngo_func_0\nfunc add(a int, b int) int { return a + b }\ngo\n2\n2\n12\n0\n1\n1\n12\n0",
    "crumbs": [
      "Clasificación",
      "Software Defects analysis"
    ]
  },
  {
    "objectID": "classification/classification_software_defects.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "href": "classification/classification_software_defects.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "title": "Software Defects analysis",
    "section": "Realizamos un analisis exploratorio sobre los datos",
    "text": "Realizamos un analisis exploratorio sobre los datos\n\nExploramos la forma general del dataset\n\n# Realizamos un analysis exploratorio sobre los datos\nprint(\"Shape:\", df.shape)\nprint(\"\\nColumns and dtypes:\")\nprint(df.dtypes)\nprint(\"\\nNumeric summary (describe):\")\ndisplay(df.describe().T)\n\nShape: (1000, 10)\n\nColumns and dtypes:\ncode                     object\nlanguage                 object\nlines_of_code             int64\ncyclomatic_complexity     int64\ntoken_count               int64\nnum_ifs                   int64\nnum_returns               int64\nnum_func_calls            int64\nast_nodes                 int64\ndefect                    int64\ndtype: object\n\nNumeric summary (describe):\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nlines_of_code\n1000.0\n3.431\n1.708847\n1.0\n2.0\n3.0\n5.0\n6.0\n\n\ncyclomatic_complexity\n1000.0\n2.914\n1.394471\n1.0\n2.0\n3.0\n4.0\n5.0\n\n\ntoken_count\n1000.0\n11.622\n1.809528\n9.0\n11.0\n12.0\n12.0\n18.0\n\n\nnum_ifs\n1000.0\n0.000\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nnum_returns\n1000.0\n0.856\n0.351265\n0.0\n1.0\n1.0\n1.0\n1.0\n\n\nnum_func_calls\n1000.0\n0.972\n0.365170\n0.0\n1.0\n1.0\n1.0\n2.0\n\n\nast_nodes\n1000.0\n11.622\n1.809528\n9.0\n11.0\n12.0\n12.0\n18.0\n\n\ndefect\n1000.0\n0.512\n0.500106\n0.0\n0.0\n1.0\n1.0\n1.0\n\n\n\n\n\n\n\n\n\nVerificamos valores nulos\n\n# Resumen de valores nulos\n\nmissing_counts = df.isna().sum()\nmissing_percent = 100 * missing_counts / len(df)\nmissing_summary = pd.concat([missing_counts, missing_percent], axis=1)\nmissing_summary.columns = [\"nulos\", \"porcentaje\"]\nprint(\"\\nNulos por columna (n y %):\")\ndisplay(missing_summary.sort_values(\"nulos\", ascending=False).head(20))\n\n\nNulos por columna (n y %):\n\n\n\n\n\n\n\n\n\nnulos\nporcentaje\n\n\n\n\ncode\n0\n0.0\n\n\nlanguage\n0\n0.0\n\n\nlines_of_code\n0\n0.0\n\n\ncyclomatic_complexity\n0\n0.0\n\n\ntoken_count\n0\n0.0\n\n\nnum_ifs\n0\n0.0\n\n\nnum_returns\n0\n0.0\n\n\nnum_func_calls\n0\n0.0\n\n\nast_nodes\n0\n0.0\n\n\ndefect\n0\n0.0\n\n\n\n\n\n\n\nRevisamos su distribution\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntarget_col = \"defect\"\nfigsize = (6, 4)\n\n# Muestra los conteos y porcentajes para la variable binaria objetivo\n\nvc = df[target_col].value_counts(dropna=False)\npct = (vc / len(df) * 100).round(2)\nprint(\"Counts:\")\nprint(vc)\nprint(\"\\nPercent:\")\nprint(pct)\n\nplt.figure(figsize=figsize)\nsns.barplot(x=vc.index.astype(str), y=vc.values)\nplt.title(f\"Target distribution: {target_col}\")\nplt.ylabel(\"count\")\nplt.xlabel(target_col)\nplt.show()\n\nCounts:\ndefect\n1    512\n0    488\nName: count, dtype: int64\n\nPercent:\ndefect\n1    51.2\n0    48.8\nName: count, dtype: float64",
    "crumbs": [
      "Clasificación",
      "Software Defects analysis"
    ]
  },
  {
    "objectID": "classification/classification_keylogger.html",
    "href": "classification/classification_keylogger.html",
    "title": "Keylogger detection",
    "section": "",
    "text": "PLANNING: - INTRO - short dataset description. - EDA - shape, dtypes, missing, class balance, sample rows, correlations. - PREPARING DATA - drop useless columns, fix dtype issues, parse timestamps, coerce numerics, encode label. - DATA SPLITTING - splitting training and testing data. - RESULTS - early results. - PREPARING MODELS - prepare hyperparameter, baseline models., baseline models. - RESULTS WITH MULTIPLES MODELS- metrics (precision/recall/f1), confusion matrix. - BALANCING - try balancing and compare. - RESULTS (after balancing) - compare metrics. - CONCLUSION - state best model, tradeoffs, next steps.",
    "crumbs": [
      "Clasificación",
      "Keylogger detection"
    ]
  },
  {
    "objectID": "classification/classification_keylogger.html#importamos-las-librerías-necesarias-y-cargamos-el-dataset",
    "href": "classification/classification_keylogger.html#importamos-las-librerías-necesarias-y-cargamos-el-dataset",
    "title": "Keylogger detection",
    "section": "Importamos las librerías necesarias y cargamos el dataset",
    "text": "Importamos las librerías necesarias y cargamos el dataset\n\nimport pandas as pd\nfrom pathlib import Path\n\nbase_dir = Path.cwd()\ncsv_file_path = base_dir.parent.parent / \"data\" / \"keylogger_detection\" / \"Keylogger_Detection_sample.csv\"\ndata = pd.read_csv(csv_file_path, low_memory=False, index_col=0)\n# Para hacer más rápido el procesamiento, tomamos una muestra del dataset\ndf = data.sample(n=1000, random_state=42)\ndf.head(1)\n\n\n\n\n\n\n\n\nSource IP\nSource Port\nDestination IP\nDestination Port\nProtocol\nTimestamp\nFlow Duration\nTotal Fwd Packets\nTotal Backward Packets\nTotal Length of Fwd Packets\n...\nmin_seg_size_forward\nActive Mean\nActive Std\nActive Max\nActive Min\nIdle Mean\nIdle Std\nIdle Max\nIdle Min\nClass\n\n\nFlow ID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n172.217.11.34-10.42.0.211-443-32906-6\n10.42.0.211\n32906.0\n172.217.11.34\n443.0\n6.0\n12/07/2017 02:05:31\n4508467.0\n2.0\n0.0\n0.0\n...\n32.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nKeylogger\n\n\n\n\n1 rows × 84 columns",
    "crumbs": [
      "Clasificación",
      "Keylogger detection"
    ]
  },
  {
    "objectID": "classification/classification_keylogger.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "href": "classification/classification_keylogger.html#realizamos-un-analisis-exploratorio-sobre-los-datos",
    "title": "Keylogger detection",
    "section": "Realizamos un analisis exploratorio sobre los datos",
    "text": "Realizamos un analisis exploratorio sobre los datos\n\nExploramos la forma general del dataset\n\n# Realizamos un analysis exploratorio sobre los datos\nn = 5\nprint(\"Shape:\", df.shape)\nprint(\"\\nColumns and dtypes:\")\nprint(df.dtypes)\nprint(\"\\nNumeric summary (describe):\")\ndisplay(df.describe().T)\n\nShape: (1000, 84)\n\nColumns and dtypes:\n Source IP            object\n Source Port         float64\n Destination IP       object\n Destination Port    float64\n Protocol            float64\n                      ...   \nIdle Mean            float64\n Idle Std            float64\n Idle Max            float64\n Idle Min            float64\nClass                 object\nLength: 84, dtype: object\n\nNumeric summary (describe):\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nSource Port\n1000.0\n3.815298e+04\n1.877217e+04\n0.0\n34250.75\n42899.5\n51987.25\n6.490400e+04\n\n\nDestination Port\n1000.0\n6.729693e+03\n1.652872e+04\n0.0\n80.00\n443.0\n443.00\n6.096000e+04\n\n\nProtocol\n1000.0\n7.806000e+00\n4.163616e+00\n0.0\n6.00\n6.0\n6.00\n1.700000e+01\n\n\nFlow Duration\n1000.0\n1.129487e+07\n2.334697e+07\n2.0\n39036.00\n471797.5\n10096081.50\n1.199892e+08\n\n\nTotal Fwd Packets\n1000.0\n7.618000e+00\n2.790492e+01\n1.0\n1.00\n2.0\n6.00\n7.050000e+02\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nActive Min\n1000.0\n1.704751e+05\n1.716989e+06\n0.0\n0.00\n0.0\n0.00\n4.993167e+07\n\n\nIdle Mean\n1000.0\n4.599871e+06\n1.548024e+07\n0.0\n0.00\n0.0\n0.00\n1.145099e+08\n\n\nIdle Std\n1000.0\n4.484078e+05\n3.680408e+06\n0.0\n0.00\n0.0\n0.00\n4.708189e+07\n\n\nIdle Max\n1000.0\n4.972753e+06\n1.636404e+07\n0.0\n0.00\n0.0\n0.00\n1.145099e+08\n\n\nIdle Min\n1000.0\n4.254974e+06\n1.512216e+07\n0.0\n0.00\n0.0\n0.00\n1.145099e+08\n\n\n\n\n80 rows × 8 columns\n\n\n\n\n\nVerificamos valores nulos\n\n# Resumen de valores nulos\n\nmissing_counts = df.isna().sum()\nmissing_percent = 100 * missing_counts / len(df)\nmissing_summary = pd.concat([missing_counts, missing_percent], axis=1)\nmissing_summary.columns = [\"nulos\", \"porcentaje\"]\nprint(\"\\nNulos por columna (n y %):\")\ndisplay(missing_summary.sort_values(\"nulos\", ascending=False).head(20))\n\n\nNulos por columna (n y %):\n\n\n\n\n\n\n\n\n\nnulos\nporcentaje\n\n\n\n\nSource IP\n0\n0.0\n\n\nURG Flag Count\n0\n0.0\n\n\nFwd Avg Bytes/Bulk\n0\n0.0\n\n\nFwd Header Length.1\n0\n0.0\n\n\nAvg Bwd Segment Size\n0\n0.0\n\n\nAvg Fwd Segment Size\n0\n0.0\n\n\nAverage Packet Size\n0\n0.0\n\n\nDown/Up Ratio\n0\n0.0\n\n\nECE Flag Count\n0\n0.0\n\n\nCWE Flag Count\n0\n0.0\n\n\nACK Flag Count\n0\n0.0\n\n\nSource Port\n0\n0.0\n\n\nPSH Flag Count\n0\n0.0\n\n\nRST Flag Count\n0\n0.0\n\n\nSYN Flag Count\n0\n0.0\n\n\nFIN Flag Count\n0\n0.0\n\n\nPacket Length Variance\n0\n0.0\n\n\nPacket Length Std\n0\n0.0\n\n\nPacket Length Mean\n0\n0.0\n\n\nMax Packet Length\n0\n0.0\n\n\n\n\n\n\n\nRevisamos su distribution\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntarget_col = \"Class\"\nfigsize = (6, 4)\n\n# Muestra los conteos y porcentajes para la variable binaria objetivo\n\nvc = df[target_col].value_counts(dropna=False)\npct = (vc / len(df) * 100).round(2)\nprint(\"Counts:\")\nprint(vc)\nprint(\"\\nPercent:\")\nprint(pct)\n\nplt.figure(figsize=figsize)\nsns.barplot(x=vc.index.astype(str), y=vc.values)\nplt.title(f\"Target distribution: {target_col}\")\nplt.ylabel(\"count\")\nplt.xlabel(target_col)\nplt.show()\n\nCounts:\nClass\nBenign       620\nKeylogger    380\nName: count, dtype: int64\n\nPercent:\nClass\nBenign       62.0\nKeylogger    38.0\nName: count, dtype: float64",
    "crumbs": [
      "Clasificación",
      "Keylogger detection"
    ]
  },
  {
    "objectID": "association-rules/02_ejemplo_1.2.html",
    "href": "association-rules/02_ejemplo_1.2.html",
    "title": "Implementación del ejemplo con python",
    "section": "",
    "text": "### Bibliotecas que necesitas Instalar:\n\n#! pip install mlxtend\n#! pip install pandas\n# Importar las bibliotecas necesarias\nimport pandas as pd\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\n# Datos de transacciones: lista de listas, donde cada sublista representa una transacción\ntransactions = [\n    ['Leche', 'Pan', 'Mantequilla'],\n    ['Leche', 'Pan'],\n    ['Leche', 'Manzana'],\n    ['Pan', 'Mantequilla'],\n    ['Leche', 'Pan', 'Mantequilla', 'Manzana'],\n    ['Manzana', 'Mantequilla']\n]\n\ntransactions\n\n[['Leche', 'Pan', 'Mantequilla'],\n ['Leche', 'Pan'],\n ['Leche', 'Manzana'],\n ['Pan', 'Mantequilla'],\n ['Leche', 'Pan', 'Mantequilla', 'Manzana'],\n ['Manzana', 'Mantequilla']]\n#Creamos una instancia de TransactionEncoder. \n# Este objeto se utiliza para transformar nuestras transacciones en una matriz booleana.\nte = TransactionEncoder()\nte\n\nTransactionEncoder()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org. TransactionEncoderiNot fittedTransactionEncoder()",
    "crumbs": [
      "Reglas de Asociación",
      "Implementación del ejemplo con python"
    ]
  },
  {
    "objectID": "association-rules/02_ejemplo_1.2.html#transactionencoder",
    "href": "association-rules/02_ejemplo_1.2.html#transactionencoder",
    "title": "Implementación del ejemplo con python",
    "section": "TransactionEncoder",
    "text": "TransactionEncoder\nTransactionEncoder - es una clase de la biblioteca mlxtend que se utiliza para convertir listas de transacciones en una matriz booleana, - lo que es especialmente útil para el análisis de asociaciones y la minería de datos.\n¿Qué es TransactionEncoder? - TransactionEncoder es un transformador que toma una lista de listas (donde cada sublista representa una transacción que contiene uno o más ítems) - y la convierte en una matriz de formato booleano o de ceros y unos. - Cada fila de la matriz resultante representa una transacción, y cada columna representa un ítem. Los valores de la matriz indican la presencia (True o 1) o la ausencia (False o 0) de un ítem en cada transacción.\n¿Qué hace TransactionEncoder?\nAjuste y Transformación:\nfit: Ajusta el codificador a los datos, identificando todos los ítems únicos en el conjunto de transacciones. transform: Convierte las transacciones en una matriz booleana basada en los ítems identificados. fit_transform: Ajusta y transforma los datos en una sola operación. Matriz Booleana: La matriz booleana generada tiene las siguientes características:\nFilas: Cada fila representa una transacción. Columnas: Cada columna representa un ítem único encontrado en las transacciones. Valores: True (o 1) indica que el ítem está presente en la transacción, y False (o 0) indica que el ítem no está presente.\n\n# Transformar los datos de transacciones en una matriz booleana\nte_ary = te.fit_transform(transactions)\nte_ary\n\narray([[ True,  True, False,  True],\n       [ True, False, False,  True],\n       [ True, False,  True, False],\n       [False,  True, False,  True],\n       [ True,  True,  True,  True],\n       [False,  True,  True, False]])\n\n\n\n# Convertir la matriz booleana en un DataFrame de pandas\n# te_ary: es la matriz booleana generada por TransactionEncoder, donde cada fila representa una transacción\n# y cada columna representa un producto. Un valor 1 indica que el producto está presente en la transacción,\n# y un valor 0 indica que no lo está.\n# columns=te.columns_: son los nombres de las columnas (los nombres de los productos) que se asignan a las columnas del DataFrame\ndf = pd.DataFrame(te_ary, columns=te.columns_)\n\n# Mostrar el DataFrame resultante para verificar la transformación\ndf\n\n\n\n\n\n\n\n\nLeche\nMantequilla\nManzana\nPan\n\n\n\n\n0\nTrue\nTrue\nFalse\nTrue\n\n\n1\nTrue\nFalse\nFalse\nTrue\n\n\n2\nTrue\nFalse\nTrue\nFalse\n\n\n3\nFalse\nTrue\nFalse\nTrue\n\n\n4\nTrue\nTrue\nTrue\nTrue\n\n\n5\nFalse\nTrue\nTrue\nFalse\n\n\n\n\n\n\n\n\n# Calcular los ítems frecuentes utilizando el algoritmo Apriori\n# Utilizamos la función apriori para encontrar ítems frecuentes en las transacciones\n# - df: El DataFrame que contiene las transacciones transformadas\n# - min_support=0.1: Definimos el soporte mínimo como 0.1 (10%). Esto significa que un ítem debe aparecer en al menos el 10% de las transacciones para ser considerado frecuente.\n# - use_colnames=True: Usamos los nombres de las columnas (los nombres de los productos) en lugar de índices numéricos\nfrequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\n\n# Mostrar los ítems frecuentes y su soporte\nprint(\"Ítems frecuentes encontrados:\")\nfrequent_itemsets\n\nÍtems frecuentes encontrados:\n\n\n\n\n\n\n\n\n\nsupport\nitemsets\n\n\n\n\n0\n0.666667\n(Leche)\n\n\n1\n0.666667\n(Mantequilla)\n\n\n2\n0.500000\n(Manzana)\n\n\n3\n0.666667\n(Pan)\n\n\n4\n0.333333\n(Mantequilla, Leche)\n\n\n5\n0.333333\n(Manzana, Leche)\n\n\n6\n0.500000\n(Pan, Leche)\n\n\n7\n0.333333\n(Manzana, Mantequilla)\n\n\n8\n0.500000\n(Mantequilla, Pan)\n\n\n9\n0.166667\n(Manzana, Pan)\n\n\n10\n0.166667\n(Manzana, Mantequilla, Leche)\n\n\n11\n0.333333\n(Mantequilla, Pan, Leche)\n\n\n12\n0.166667\n(Manzana, Pan, Leche)\n\n\n13\n0.166667\n(Manzana, Mantequilla, Pan)\n\n\n14\n0.166667\n(Manzana, Mantequilla, Pan, Leche)\n\n\n\n\n\n\n\n\n# Generar las reglas de asociación\n# Utilizamos la función association_rules para generar las reglas a partir de los ítems frecuentes.\n# - frequent_itemsets: contiene los ítems frecuentes calculados con el algoritmo Apriori.\n# - metric: definimos la métrica \"confidence\" para evaluar las reglas.\n# - min_threshold: establecemos un umbral mínimo de 0.5 (50%) para la métrica de confianza.\nrules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n\n# Filtrar y mostrar las reglas\n# Seleccionamos las columnas más relevantes para mostrar: antecedentes, consecuentes, soporte, confianza y lift.\nrules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\nprint(\"Reglas de asociación generadas:\")\nrules\n\nReglas de asociación generadas:\n\n\n\n\n\n\n\n\n\nantecedents\nconsequents\nsupport\nconfidence\nlift\n\n\n\n\n0\n(Mantequilla)\n(Leche)\n0.333333\n0.500000\n0.750\n\n\n1\n(Leche)\n(Mantequilla)\n0.333333\n0.500000\n0.750\n\n\n2\n(Manzana)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n3\n(Leche)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n4\n(Pan)\n(Leche)\n0.500000\n0.750000\n1.125\n\n\n5\n(Leche)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n6\n(Manzana)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n7\n(Mantequilla)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n8\n(Mantequilla)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n9\n(Pan)\n(Mantequilla)\n0.500000\n0.750000\n1.125\n\n\n10\n(Manzana, Mantequilla)\n(Leche)\n0.166667\n0.500000\n0.750\n\n\n11\n(Manzana, Leche)\n(Mantequilla)\n0.166667\n0.500000\n0.750\n\n\n12\n(Mantequilla, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n13\n(Mantequilla, Pan)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n14\n(Mantequilla, Leche)\n(Pan)\n0.333333\n1.000000\n1.500\n\n\n15\n(Pan, Leche)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n16\n(Mantequilla)\n(Pan, Leche)\n0.333333\n0.500000\n1.000\n\n\n17\n(Pan)\n(Mantequilla, Leche)\n0.333333\n0.500000\n1.500\n\n\n18\n(Leche)\n(Mantequilla, Pan)\n0.333333\n0.500000\n1.000\n\n\n19\n(Manzana, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n20\n(Manzana, Leche)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n21\n(Manzana, Mantequilla)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n22\n(Manzana, Pan)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n23\n(Manzana, Mantequilla, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n24\n(Manzana, Mantequilla, Leche)\n(Pan)\n0.166667\n1.000000\n1.500\n\n\n25\n(Manzana, Pan, Leche)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n26\n(Mantequilla, Pan, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n27\n(Manzana, Mantequilla)\n(Pan, Leche)\n0.166667\n0.500000\n1.000\n\n\n28\n(Manzana, Pan)\n(Mantequilla, Leche)\n0.166667\n1.000000\n3.000\n\n\n29\n(Manzana, Leche)\n(Mantequilla, Pan)\n0.166667\n0.500000\n1.000\n\n\n30\n(Mantequilla, Leche)\n(Manzana, Pan)\n0.166667\n0.500000\n3.000\n\n\n\n\n\n\n\n\n# Filtrar y mostrar las reglas\n# Seleccionamos solo las columnas relevantes para mostrar\nrules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\nprint(\"Reglas de asociación generadas:\")\nrules\n\nReglas de asociación generadas:\n\n\n\n\n\n\n\n\n\nantecedents\nconsequents\nsupport\nconfidence\nlift\n\n\n\n\n0\n(Mantequilla)\n(Leche)\n0.333333\n0.500000\n0.750\n\n\n1\n(Leche)\n(Mantequilla)\n0.333333\n0.500000\n0.750\n\n\n2\n(Manzana)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n3\n(Leche)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n4\n(Pan)\n(Leche)\n0.500000\n0.750000\n1.125\n\n\n5\n(Leche)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n6\n(Manzana)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n7\n(Mantequilla)\n(Manzana)\n0.333333\n0.500000\n1.000\n\n\n8\n(Mantequilla)\n(Pan)\n0.500000\n0.750000\n1.125\n\n\n9\n(Pan)\n(Mantequilla)\n0.500000\n0.750000\n1.125\n\n\n10\n(Manzana, Mantequilla)\n(Leche)\n0.166667\n0.500000\n0.750\n\n\n11\n(Manzana, Leche)\n(Mantequilla)\n0.166667\n0.500000\n0.750\n\n\n12\n(Mantequilla, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n13\n(Mantequilla, Pan)\n(Leche)\n0.333333\n0.666667\n1.000\n\n\n14\n(Mantequilla, Leche)\n(Pan)\n0.333333\n1.000000\n1.500\n\n\n15\n(Pan, Leche)\n(Mantequilla)\n0.333333\n0.666667\n1.000\n\n\n16\n(Mantequilla)\n(Pan, Leche)\n0.333333\n0.500000\n1.000\n\n\n17\n(Pan)\n(Mantequilla, Leche)\n0.333333\n0.500000\n1.500\n\n\n18\n(Leche)\n(Mantequilla, Pan)\n0.333333\n0.500000\n1.000\n\n\n19\n(Manzana, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n20\n(Manzana, Leche)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n21\n(Manzana, Mantequilla)\n(Pan)\n0.166667\n0.500000\n0.750\n\n\n22\n(Manzana, Pan)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n23\n(Manzana, Mantequilla, Pan)\n(Leche)\n0.166667\n1.000000\n1.500\n\n\n24\n(Manzana, Mantequilla, Leche)\n(Pan)\n0.166667\n1.000000\n1.500\n\n\n25\n(Manzana, Pan, Leche)\n(Mantequilla)\n0.166667\n1.000000\n1.500\n\n\n26\n(Mantequilla, Pan, Leche)\n(Manzana)\n0.166667\n0.500000\n1.000\n\n\n27\n(Manzana, Mantequilla)\n(Pan, Leche)\n0.166667\n0.500000\n1.000\n\n\n28\n(Manzana, Pan)\n(Mantequilla, Leche)\n0.166667\n1.000000\n3.000\n\n\n29\n(Manzana, Leche)\n(Mantequilla, Pan)\n0.166667\n0.500000\n1.000\n\n\n30\n(Mantequilla, Leche)\n(Manzana, Pan)\n0.166667\n0.500000\n3.000\n\n\n\n\n\n\n\n\n# Interpretación del resultado\n# Iterar sobre cada regla para imprimir una interpretación más clara\nfor idx, rule in rules.iterrows():\n    # Convertir los conjuntos de antecedentes y consecuentes en cadenas de texto\n    antecedents = ', '.join(list(rule['antecedents']))\n    consequents = ', '.join(list(rule['consequents']))\n    support = rule['support']\n    confidence = rule['confidence']\n    lift = rule['lift']\n    \n    # Imprimir la interpretación de cada regla\n    print(f\"Regla: {antecedents} -&gt; {consequents}\")\n    print(f\"  Soporte: {support:.2f}\")\n    print(f\"  Confianza: {confidence:.2f}\")\n    print(f\"  Lift: {lift:.2f}\")\n    print(f\"  Interpretación: Si un cliente compra {antecedents}, hay una confianza del {confidence:.2%} de que también comprará {consequents}. El lift de {lift:.2f} indica que esta relación es {lift:.2f} veces más probable que si los productos fueran independientes.\\n\")\n\nRegla: Mantequilla -&gt; Leche\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretación: Si un cliente compra Mantequilla, hay una confianza del 50.00% de que también comprará Leche. El lift de 0.75 indica que esta relación es 0.75 veces más probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Mantequilla\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretación: Si un cliente compra Leche, hay una confianza del 50.00% de que también comprará Mantequilla. El lift de 0.75 indica que esta relación es 0.75 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana -&gt; Leche\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretación: Si un cliente compra Manzana, hay una confianza del 66.67% de que también comprará Leche. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Manzana\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Leche, hay una confianza del 50.00% de que también comprará Manzana. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Pan -&gt; Leche\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretación: Si un cliente compra Pan, hay una confianza del 75.00% de que también comprará Leche. El lift de 1.12 indica que esta relación es 1.12 veces más probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Pan\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretación: Si un cliente compra Leche, hay una confianza del 75.00% de que también comprará Pan. El lift de 1.12 indica que esta relación es 1.12 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana -&gt; Mantequilla\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretación: Si un cliente compra Manzana, hay una confianza del 66.67% de que también comprará Mantequilla. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla -&gt; Manzana\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Mantequilla, hay una confianza del 50.00% de que también comprará Manzana. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla -&gt; Pan\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretación: Si un cliente compra Mantequilla, hay una confianza del 75.00% de que también comprará Pan. El lift de 1.12 indica que esta relación es 1.12 veces más probable que si los productos fueran independientes.\n\nRegla: Pan -&gt; Mantequilla\n  Soporte: 0.50\n  Confianza: 0.75\n  Lift: 1.12\n  Interpretación: Si un cliente compra Pan, hay una confianza del 75.00% de que también comprará Mantequilla. El lift de 1.12 indica que esta relación es 1.12 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla -&gt; Leche\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretación: Si un cliente compra Manzana, Mantequilla, hay una confianza del 50.00% de que también comprará Leche. El lift de 0.75 indica que esta relación es 0.75 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Leche -&gt; Mantequilla\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretación: Si un cliente compra Manzana, Leche, hay una confianza del 50.00% de que también comprará Mantequilla. El lift de 0.75 indica que esta relación es 0.75 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Leche -&gt; Manzana\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Mantequilla, Leche, hay una confianza del 50.00% de que también comprará Manzana. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Pan -&gt; Leche\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretación: Si un cliente compra Mantequilla, Pan, hay una confianza del 66.67% de que también comprará Leche. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Leche -&gt; Pan\n  Soporte: 0.33\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretación: Si un cliente compra Mantequilla, Leche, hay una confianza del 100.00% de que también comprará Pan. El lift de 1.50 indica que esta relación es 1.50 veces más probable que si los productos fueran independientes.\n\nRegla: Pan, Leche -&gt; Mantequilla\n  Soporte: 0.33\n  Confianza: 0.67\n  Lift: 1.00\n  Interpretación: Si un cliente compra Pan, Leche, hay una confianza del 66.67% de que también comprará Mantequilla. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla -&gt; Pan, Leche\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Mantequilla, hay una confianza del 50.00% de que también comprará Pan, Leche. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Pan -&gt; Mantequilla, Leche\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.50\n  Interpretación: Si un cliente compra Pan, hay una confianza del 50.00% de que también comprará Mantequilla, Leche. El lift de 1.50 indica que esta relación es 1.50 veces más probable que si los productos fueran independientes.\n\nRegla: Leche -&gt; Mantequilla, Pan\n  Soporte: 0.33\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Leche, hay una confianza del 50.00% de que también comprará Mantequilla, Pan. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan -&gt; Leche\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretación: Si un cliente compra Manzana, Pan, hay una confianza del 100.00% de que también comprará Leche. El lift de 1.50 indica que esta relación es 1.50 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Leche -&gt; Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretación: Si un cliente compra Manzana, Leche, hay una confianza del 50.00% de que también comprará Pan. El lift de 0.75 indica que esta relación es 0.75 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla -&gt; Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 0.75\n  Interpretación: Si un cliente compra Manzana, Mantequilla, hay una confianza del 50.00% de que también comprará Pan. El lift de 0.75 indica que esta relación es 0.75 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan -&gt; Mantequilla\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretación: Si un cliente compra Manzana, Pan, hay una confianza del 100.00% de que también comprará Mantequilla. El lift de 1.50 indica que esta relación es 1.50 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla, Pan -&gt; Leche\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretación: Si un cliente compra Manzana, Mantequilla, Pan, hay una confianza del 100.00% de que también comprará Leche. El lift de 1.50 indica que esta relación es 1.50 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla, Leche -&gt; Pan\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretación: Si un cliente compra Manzana, Mantequilla, Leche, hay una confianza del 100.00% de que también comprará Pan. El lift de 1.50 indica que esta relación es 1.50 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan, Leche -&gt; Mantequilla\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 1.50\n  Interpretación: Si un cliente compra Manzana, Pan, Leche, hay una confianza del 100.00% de que también comprará Mantequilla. El lift de 1.50 indica que esta relación es 1.50 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Pan, Leche -&gt; Manzana\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Mantequilla, Pan, Leche, hay una confianza del 50.00% de que también comprará Manzana. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Mantequilla -&gt; Pan, Leche\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Manzana, Mantequilla, hay una confianza del 50.00% de que también comprará Pan, Leche. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Pan -&gt; Mantequilla, Leche\n  Soporte: 0.17\n  Confianza: 1.00\n  Lift: 3.00\n  Interpretación: Si un cliente compra Manzana, Pan, hay una confianza del 100.00% de que también comprará Mantequilla, Leche. El lift de 3.00 indica que esta relación es 3.00 veces más probable que si los productos fueran independientes.\n\nRegla: Manzana, Leche -&gt; Mantequilla, Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 1.00\n  Interpretación: Si un cliente compra Manzana, Leche, hay una confianza del 50.00% de que también comprará Mantequilla, Pan. El lift de 1.00 indica que esta relación es 1.00 veces más probable que si los productos fueran independientes.\n\nRegla: Mantequilla, Leche -&gt; Manzana, Pan\n  Soporte: 0.17\n  Confianza: 0.50\n  Lift: 3.00\n  Interpretación: Si un cliente compra Mantequilla, Leche, hay una confianza del 50.00% de que también comprará Manzana, Pan. El lift de 3.00 indica que esta relación es 3.00 veces más probable que si los productos fueran independientes.",
    "crumbs": [
      "Reglas de Asociación",
      "Implementación del ejemplo con python"
    ]
  },
  {
    "objectID": "association-rules/03_ejercicio.html",
    "href": "association-rules/03_ejercicio.html",
    "title": "Determine las reglas de asociación para el siguiente conjunto de transacciones",
    "section": "",
    "text": "['Leche', 'Pan', 'Mantequilla']\n['Leche', 'Pan']\n['Leche', 'Manzana']\n['Pan', 'Mantequilla']\n['Leche', 'Pan', 'Mantequilla', 'Manzana']\n['Manzana', 'Mantequilla']\n['Leche', 'Manzana', 'Cereal']\n['Pan', 'Cereal']\n['Leche', 'Pan', 'Cereal']\n['Mantequilla', 'Manzana', 'Cereal']\n['Leche', 'Cereal', 'Galletas']\n['Pan', 'Galletas']\n['Leche', 'Pan', 'Galletas']\n['Manzana', 'Galletas']\n['Leche', 'Manzana', 'Galletas']\n['Pan', 'Mantequilla', 'Cereal']\n['Leche', 'Mantequilla', 'Cereal']\n['Leche', 'Pan', 'Manzana', 'Galletas']\n['Manzana', 'Mantequilla', 'Galletas']\n['Leche', 'Cereal', 'Manzana', 'Galletas']",
    "crumbs": [
      "Reglas de Asociación",
      "Determine las reglas de asociación para el siguiente conjunto de transacciones"
    ]
  }
]